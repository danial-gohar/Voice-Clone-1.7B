{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHECjALiQ396"
   },
   "source": [
    "# üéôÔ∏è MOSS-TTS 1.7B  (Zero-Shot Voice Cloning)\n",
    "### Free Colab Notebook (T4 GPU) | Made with ‚ù§Ô∏è by **Danial Gohar @ Mozo Technologies**\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "  <img src=\"https://img.shields.io/badge/MozoTechnologies-FF6B00?style=for-the-badge&logoColor=white\" />\n",
    "  <img src=\"https://img.shields.io/badge/Colab-Free%20Tier-orange?style=for-the-badge&logo=googlecolab&logoColor=white\" />\n",
    "  <img src=\"https://img.shields.io/badge/Model-1.7B%20Params-black?style=for-the-badge\" />\n",
    "\n",
    "  <br><br>\n",
    "\n",
    "  <a href=\"https://mozotechnologies.com\">\n",
    "    <img src=\"https://img.shields.io/badge/üåê%20Visit%20Website-FF6B00?style=for-the-badge&logoColor=white\" />\n",
    "  </a>\n",
    "  &nbsp;\n",
    "  <a href=\"https://www.linkedin.com/company/mozotech/\">\n",
    "    <img src=\"https://img.shields.io/badge/Follow%20on%20LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white\" />\n",
    "  </a>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### üìñ What is this Notebook?\n",
    "\n",
    "This notebook lets you run **MOSS-TTS 1.7B** ‚Äî a state-of-the-art **zero-shot text-to-speech** and **voice cloning** model ‚Äî entirely **free** on Google Colab's T4 GPU.\n",
    "\n",
    "**Key Features:**\n",
    "- üó£Ô∏è **Zero-Shot Voice Cloning** ‚Äî Clone any voice from a short audio reference\n",
    "- üéµ **High-Quality TTS** ‚Äî 1.7 billion parameter model for natural speech\n",
    "- ‚ö° **T4 Optimized** ‚Äî Runs on Colab free tier (no Pro needed!)\n",
    "- üéõÔ∏è **Quality Presets** ‚Äî From fast drafts (8 RVQ) to maximum quality (32 RVQ)\n",
    "- üéöÔ∏è **Full Control** ‚Äî Temperature, top-p, top-k, repetition penalty, speed\n",
    "- üåê **Gradio UI** ‚Äî Beautiful web interface with shareable public link\n",
    "\n",
    "### üöÄ How to Use\n",
    "1. Make sure **Runtime ‚Üí Change runtime type ‚Üí T4 GPU** is selected\n",
    "2. Run all cells in order (Runtime ‚Üí Run all)\n",
    "3. Wait for the Gradio link to appear (~5-8 min on first run)\n",
    "4. Open the public link and start generating speech!\n",
    "\n",
    "### üìå Credits\n",
    "- **Model:** [MOSS-TTS](https://github.com/OpenMOSS/MOSS-TTS) by OpenMOSS Team\n",
    "- **Notebook:** Optimized & packaged by **Danial Gohar** @ [Mozo Technologies](https://mozotechnologies.com)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTzElGi5Q39-"
   },
   "source": [
    "### üîç Step 1: Check GPU\n",
    "Let's verify that a **T4 GPU** is available. If you see \"Tesla T4\", you're good to go!\n",
    "If not, go to **Runtime ‚Üí Change runtime type ‚Üí T4 GPU**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63DZkNHPQ39_"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-3Ow5Z-Q39_"
   },
   "source": [
    "### üì¶ Step 2: Install Dependencies\n",
    "Installing PyTorch (CUDA 11.8), Transformers, Gradio, and other required packages.\n",
    "This takes ~2-3 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sedwX-rZQ39_"
   },
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers accelerate librosa soundfile gradio\n",
    "!pip install -q einops omegaconf pyyaml scipy datasets sentencepiece protobuf\n",
    "print(\"‚úÖ  Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yjCSxt4Q3-A"
   },
   "source": [
    "### üì• Step 3: Clone MOSS-TTS Repository\n",
    "Cloning the official MOSS-TTS repo from GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3DQ-FPeQ3-A"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/OpenMOSS/MOSS-TTS.git\n",
    "%cd MOSS-TTS\n",
    "print(\"‚úÖ MOSS-TTS repository cloned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQrAYaLoQ3-A"
   },
   "source": [
    "### ‚öôÔ∏è Step 4: Load Model & Launch Gradio Interface\n",
    "This cell loads the **MOSS-TTS 1.7B** model and launches a **Gradio** web UI.\n",
    "\n",
    "**First run downloads ~13GB** of model weights ‚Äî this takes ~5-8 minutes.\n",
    "After that, you'll get a **public Gradio link** you can share with anyone!\n",
    "\n",
    "> üí° **Tip:** Use the **Fast (8 RVQ)** preset for the longest audio on free tier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "solYY_fRQ3-A"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoModel, AutoProcessor, GenerationConfig\n",
    "import gradio as gr\n",
    "import os\n",
    "from datetime import datetime\n",
    "import importlib.util\n",
    "import traceback\n",
    "import gc\n",
    "import time\n",
    "import atexit\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Memory optimization settings for T4\n",
    "torch.backends.cuda.enable_cudnn_sdp(True)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "\n",
    "class DelayGenerationConfig(GenerationConfig):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layers = kwargs.get(\"layers\", [{} for _ in range(32)])\n",
    "        self.do_samples = kwargs.get(\"do_samples\", None)\n",
    "        self.n_vq_for_inference = 32\n",
    "\n",
    "# Global variables\n",
    "model = None\n",
    "processor = None\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "def cleanup_model():\n",
    "    \"\"\"Unload model from GPU memory\"\"\"\n",
    "    global model, processor\n",
    "    if model is not None:\n",
    "        print(\"üßπ Cleaning up model from GPU...\")\n",
    "        del model\n",
    "        model = None\n",
    "    if processor is not None:\n",
    "        if hasattr(processor, 'audio_tokenizer'):\n",
    "            del processor.audio_tokenizer\n",
    "        del processor\n",
    "        processor = None\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"‚úÖ GPU memory cleared!\")\n",
    "\n",
    "atexit.register(cleanup_model)\n",
    "\n",
    "def resolve_attn_implementation() -> str:\n",
    "    if device == \"cuda\":\n",
    "        return \"sdpa\"\n",
    "    return \"eager\"\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load model with optimized settings\"\"\"\n",
    "    global model, processor\n",
    "\n",
    "    if model is None:\n",
    "        print(\"üîÑ Loading MOSS-TTS (this takes ~5 min on first run)...\")\n",
    "\n",
    "        attn_implementation = resolve_attn_implementation()\n",
    "        print(f\"Using attention: {attn_implementation}\")\n",
    "\n",
    "        processor = AutoProcessor.from_pretrained(\n",
    "            \"OpenMOSS-Team/MOSS-TTS-Local-Transformer\",\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        processor.audio_tokenizer = processor.audio_tokenizer.to(device)\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        model = AutoModel.from_pretrained(\n",
    "            \"OpenMOSS-Team/MOSS-TTS-Local-Transformer\",\n",
    "            trust_remote_code=True,\n",
    "            attn_implementation=attn_implementation,\n",
    "            torch_dtype=dtype,\n",
    "            low_cpu_mem_usage=True,\n",
    "        ).to(device)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            vram = torch.cuda.memory_allocated() / 1024**3\n",
    "            print(f\"‚úÖ Model loaded! VRAM: {vram:.2f}GB\")\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "PRESETS = {\n",
    "    \"Fast (8 RVQ)\": {\n",
    "        \"n_vq\": 8,\n",
    "        \"text_temp\": 1.5,\n",
    "        \"audio_temp\": 0.95,\n",
    "        \"text_top_p\": 1.0,\n",
    "        \"audio_top_p\": 0.95,\n",
    "        \"text_top_k\": 50,\n",
    "        \"audio_top_k\": 50,\n",
    "        \"audio_rep_pen\": 1.1\n",
    "    },\n",
    "    \"Balanced (16 RVQ)\": {\n",
    "        \"n_vq\": 16,\n",
    "        \"text_temp\": 1.5,\n",
    "        \"audio_temp\": 0.95,\n",
    "        \"text_top_p\": 1.0,\n",
    "        \"audio_top_p\": 0.95,\n",
    "        \"text_top_k\": 50,\n",
    "        \"audio_top_k\": 50,\n",
    "        \"audio_rep_pen\": 1.1\n",
    "    },\n",
    "    \"High Quality (24 RVQ)\": {\n",
    "        \"n_vq\": 24,\n",
    "        \"text_temp\": 1.5,\n",
    "        \"audio_temp\": 0.95,\n",
    "        \"text_top_p\": 1.0,\n",
    "        \"audio_top_p\": 0.95,\n",
    "        \"text_top_k\": 50,\n",
    "        \"audio_top_k\": 50,\n",
    "        \"audio_rep_pen\": 1.1\n",
    "    },\n",
    "    \"Maximum (32 RVQ)\": {\n",
    "        \"n_vq\": 32,\n",
    "        \"text_temp\": 1.5,\n",
    "        \"audio_temp\": 0.95,\n",
    "        \"text_top_p\": 1.0,\n",
    "        \"audio_top_p\": 0.95,\n",
    "        \"text_top_k\": 50,\n",
    "        \"audio_top_k\": 50,\n",
    "        \"audio_rep_pen\": 1.1\n",
    "    }\n",
    "}\n",
    "\n",
    "def apply_preset(preset_name):\n",
    "    \"\"\"Return preset values\"\"\"\n",
    "    preset = PRESETS[preset_name]\n",
    "    return (\n",
    "        preset[\"n_vq\"],\n",
    "        preset[\"text_temp\"],\n",
    "        preset[\"text_top_p\"],\n",
    "        preset[\"text_top_k\"],\n",
    "        preset[\"audio_temp\"],\n",
    "        preset[\"audio_top_p\"],\n",
    "        preset[\"audio_top_k\"],\n",
    "        preset[\"audio_rep_pen\"]\n",
    "    )\n",
    "\n",
    "def generate_speech(\n",
    "    text,\n",
    "    reference_audio,\n",
    "    max_new_tokens,\n",
    "    speed,\n",
    "    text_temp,\n",
    "    text_top_p,\n",
    "    text_top_k,\n",
    "    audio_temp,\n",
    "    audio_top_p,\n",
    "    audio_top_k,\n",
    "    audio_repetition_penalty,\n",
    "    n_vq,\n",
    "    progress=gr.Progress()\n",
    "):\n",
    "    \"\"\"Generate TTS with memory-efficient long-form generation\"\"\"\n",
    "\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return None, \"‚ö†Ô∏è Please enter text!\"\n",
    "\n",
    "    try:\n",
    "        os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "        progress(0, desc=\"Loading model...\")\n",
    "        model, processor = load_model()\n",
    "\n",
    "        text_length = len(text)\n",
    "        estimated_duration = max_new_tokens / 12.5\n",
    "\n",
    "        status = f\"üìù Text: {text_length:,} chars\\n\"\n",
    "        status += f\"üéØ Target: {max_new_tokens} tokens (~{estimated_duration/60:.1f} min)\\n\\n\"\n",
    "\n",
    "        yield None, status\n",
    "\n",
    "        # Build conversation\n",
    "        progress(0.1, desc=\"Processing...\")\n",
    "        if reference_audio is not None:\n",
    "            status += f\"üéôÔ∏è Voice cloning: {os.path.basename(reference_audio)}\\n\"\n",
    "            conversations = [[\n",
    "                processor.build_user_message(text=text, reference=[reference_audio])\n",
    "            ]]\n",
    "        else:\n",
    "            status += \"üéôÔ∏è Default voice\\n\"\n",
    "            conversations = [[\n",
    "                processor.build_user_message(text=text)\n",
    "            ]]\n",
    "\n",
    "        yield None, status\n",
    "\n",
    "        # Process input\n",
    "        batch = processor(conversations, mode=\"generation\")\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        # Fix temperature bug\n",
    "        if text_temp == 1.0:\n",
    "            text_temp = 1.001\n",
    "        if audio_temp == 1.0:\n",
    "            audio_temp = 1.001\n",
    "\n",
    "        # Generation config\n",
    "        generation_config = DelayGenerationConfig()\n",
    "        generation_config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "        generation_config.eos_token_id = 151653\n",
    "        generation_config.max_new_tokens = max_new_tokens\n",
    "        generation_config.use_cache = True\n",
    "        generation_config.do_sample = True\n",
    "        generation_config.num_beams = 1\n",
    "\n",
    "        generation_config.n_vq_for_inference = n_vq\n",
    "        generation_config.do_samples = [True] * (n_vq + 1)\n",
    "        generation_config.layers = [\n",
    "            {\n",
    "                \"repetition_penalty\": 1.0,\n",
    "                \"temperature\": text_temp,\n",
    "                \"top_p\": text_top_p,\n",
    "                \"top_k\": text_top_k\n",
    "            }\n",
    "        ] + [\n",
    "            {\n",
    "                \"repetition_penalty\": audio_repetition_penalty,\n",
    "                \"temperature\": audio_temp,\n",
    "                \"top_p\": audio_top_p,\n",
    "                \"top_k\": audio_top_k\n",
    "            }\n",
    "        ] * n_vq\n",
    "\n",
    "        # Clear cache\n",
    "        progress(0.2, desc=\"Clearing cache...\")\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        status += f\"\\nüéµ Generating...\\n\"\n",
    "        yield None, status\n",
    "\n",
    "        # Generate\n",
    "        start_time = time.time()\n",
    "        progress(0.3, desc=\"Generating...\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "\n",
    "        gen_time = time.time() - start_time\n",
    "\n",
    "        progress(0.85, desc=\"Decoding...\")\n",
    "        status += f\"‚úÖ Generated in {gen_time:.1f}s\\n\"\n",
    "        status += \"üîä Decoding...\\n\"\n",
    "        yield None, status\n",
    "\n",
    "        # Decode\n",
    "        decoded_messages = processor.decode(outputs)\n",
    "        audio = decoded_messages[0].audio_codes_list[0]\n",
    "\n",
    "        # Clear memory\n",
    "        if device == \"cuda\":\n",
    "            del outputs, input_ids, attention_mask, batch, decoded_messages\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            gc.collect()\n",
    "\n",
    "        # Speed\n",
    "        progress(0.94, desc=\"Speed adjust...\")\n",
    "        if speed != 1.0:\n",
    "            sample_rate = processor.model_config.sampling_rate\n",
    "            new_sample_rate = int(sample_rate * speed)\n",
    "            resampler = torchaudio.transforms.Resample(\n",
    "                orig_freq=sample_rate,\n",
    "                new_freq=new_sample_rate\n",
    "            )\n",
    "            audio_resampled = resampler(audio.unsqueeze(0)).squeeze(0)\n",
    "            resampler_back = torchaudio.transforms.Resample(\n",
    "                orig_freq=new_sample_rate,\n",
    "                new_freq=sample_rate\n",
    "            )\n",
    "            audio = resampler_back(audio_resampled.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        progress(0.97, desc=\"Saving...\")\n",
    "\n",
    "        # Save\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"outputs/moss_tts_{timestamp}.wav\"\n",
    "        torchaudio.save(\n",
    "            output_path,\n",
    "            audio.unsqueeze(0),\n",
    "            processor.model_config.sampling_rate\n",
    "        )\n",
    "\n",
    "        duration = len(audio) / processor.model_config.sampling_rate\n",
    "        vram = torch.cuda.memory_allocated() / 1024**3 if device == \"cuda\" else 0\n",
    "        rtf = gen_time / duration if duration > 0 else 0\n",
    "\n",
    "        progress(1.0, desc=\"Done!\")\n",
    "\n",
    "        status += f\"\\nüéâ SUCCESS!\\n\"\n",
    "        status += f\"üìè Audio: {duration:.1f}s ({duration/60:.2f} min)\\n\"\n",
    "        status += f\"‚è±Ô∏è Generation: {gen_time:.1f}s ({gen_time/60:.1f} min)\\n\"\n",
    "        status += f\"üöÄ RTF: {rtf:.2f}x\\n\"\n",
    "        status += f\"üéöÔ∏è Speed: {speed}x\\n\"\n",
    "        status += f\"üìä VRAM: {vram:.2f}GB\\n\"\n",
    "        status += f\"üéõÔ∏è RVQ: {n_vq}/32\\n\"\n",
    "        status += f\"üíæ {output_path}\"\n",
    "\n",
    "        yield output_path, status\n",
    "\n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        error_msg = f\"‚ùå OUT OF MEMORY!\\n\\n\"\n",
    "        error_msg += f\"Tried: {max_new_tokens} tokens with {n_vq} RVQ\\n\\n\"\n",
    "        error_msg += f\"Solutions:\\n\"\n",
    "        error_msg += f\"1. Reduce Max Tokens\\n\"\n",
    "        error_msg += f\"2. Use Fast (8 RVQ) preset\\n\"\n",
    "        error_msg += f\"3. Click 'Clear GPU' and retry\\n\\n\"\n",
    "        error_msg += f\"T4 Limits:\\n\"\n",
    "        error_msg += f\"‚Ä¢ 8 RVQ: ~7200 tokens (12 min)\\n\"\n",
    "        error_msg += f\"‚Ä¢ 16 RVQ: ~4800 tokens (8 min)\\n\"\n",
    "        error_msg += f\"‚Ä¢ 24 RVQ: ~3000 tokens (5 min)\\n\"\n",
    "        error_msg += f\"‚Ä¢ 32 RVQ: ~2400 tokens (4 min)\"\n",
    "        yield None, error_msg\n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Error: {str(e)}\\n\\n{traceback.format_exc()}\"\n",
    "        yield None, error_msg\n",
    "\n",
    "# =============================================\n",
    "# GRADIO INTERFACE ‚Äî MOZO TECHNOLOGIES BRANDING\n",
    "# =============================================\n",
    "\n",
    "custom_css = \"\"\"\n",
    "/* ============ MOZO TECHNOLOGIES ‚Äî ORANGE & BLACK THEME ============ */\n",
    ".mozo-header {\n",
    "    background: linear-gradient(135deg, #FF6B00 0%, #1a1a1a 75%, #111111 100%);\n",
    "    padding: 24px 20px;\n",
    "    border-radius: 14px;\n",
    "    margin-bottom: 18px;\n",
    "    text-align: center;\n",
    "    color: white;\n",
    "    border: 2px solid #FF6B00;\n",
    "    box-shadow: 0 4px 24px rgba(255,107,0,0.3);\n",
    "}\n",
    ".mozo-header h1 {\n",
    "    margin: 0 0 6px 0;\n",
    "    font-size: 1.9em;\n",
    "    color: white !important;\n",
    "    letter-spacing: 0.4px;\n",
    "}\n",
    ".mozo-header p {\n",
    "    margin: 4px 0;\n",
    "    opacity: 0.93;\n",
    "    color: #f0f0f0 !important;\n",
    "}\n",
    ".mozo-divider {\n",
    "    height: 2px;\n",
    "    background: linear-gradient(90deg, transparent, #FF6B00, transparent);\n",
    "    margin: 10px auto;\n",
    "    width: 55%;\n",
    "    border-radius: 2px;\n",
    "}\n",
    ".social-buttons {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    gap: 14px;\n",
    "    margin-top: 14px;\n",
    "    flex-wrap: wrap;\n",
    "}\n",
    ".social-buttons a {\n",
    "    display: inline-flex;\n",
    "    align-items: center;\n",
    "    gap: 7px;\n",
    "    padding: 9px 20px;\n",
    "    border-radius: 8px;\n",
    "    text-decoration: none;\n",
    "    font-weight: 700;\n",
    "    font-size: 0.95em;\n",
    "    transition: transform 0.2s, box-shadow 0.2s;\n",
    "}\n",
    ".social-buttons a:hover {\n",
    "    transform: translateY(-3px);\n",
    "    box-shadow: 0 6px 18px rgba(0,0,0,0.4);\n",
    "}\n",
    ".web-btn {\n",
    "    background: #FF6B00;\n",
    "    color: white !important;\n",
    "    border: 1px solid #ff8c33;\n",
    "}\n",
    ".li-btn {\n",
    "    background: #0A66C2;\n",
    "    color: white !important;\n",
    "}\n",
    ".mozo-footer {\n",
    "    text-align: center;\n",
    "    padding: 16px;\n",
    "    margin-top: 18px;\n",
    "    border-radius: 12px;\n",
    "    background: linear-gradient(135deg, #1a1a1a 0%, #FF6B00 100%);\n",
    "    color: white;\n",
    "    font-size: 0.9em;\n",
    "    border: 2px solid #FF6B00;\n",
    "    box-shadow: 0 4px 20px rgba(255,107,0,0.2);\n",
    "}\n",
    ".mozo-footer a {\n",
    "    color: #FFB347 !important;\n",
    "    text-decoration: none;\n",
    "    font-weight: 700;\n",
    "}\n",
    ".mozo-footer a:hover { color: #ffffff !important; }\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"MOSS-TTS by Mozo Technologies\",\n",
    "    theme=gr.themes.Soft(),\n",
    "    css=custom_css\n",
    ") as demo:\n",
    "\n",
    "    # ---- HEADER WITH MOZO BRANDING ----\n",
    "    gr.HTML(\"\"\"\n",
    "    <div class=\"mozo-header\">\n",
    "        <h1>üéôÔ∏è MOSS-TTS 1.7B &mdash; Zero-Shot Voice Cloning</h1>\n",
    "        <div class=\"mozo-divider\"></div>\n",
    "        <p>1.7B parameter model &nbsp;&bull;&nbsp; TTS &amp; voice cloning &nbsp;&bull;&nbsp; Colab Free Tier (T4 GPU)</p>\n",
    "        <p style=\"font-size:0.82em; opacity:0.78; margin-top:6px;\">\n",
    "            Model by <b>OpenMOSS</b> &nbsp;&bull;&nbsp; Notebook by <b>Danial Gohar</b> @ <b>Mozo Technologies</b>\n",
    "        </p>\n",
    "        <div class=\"social-buttons\">\n",
    "            <a href=\"https://mozotechnologies.com\" target=\"_blank\" class=\"web-btn\">\n",
    "                üåê mozotechnologies.com\n",
    "            </a>\n",
    "            <a href=\"https://www.linkedin.com/company/mozotech/\" target=\"_blank\" class=\"li-btn\">\n",
    "                üíº Follow on LinkedIn\n",
    "            </a>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            text_input = gr.Textbox(\n",
    "                label=\"üìù Text\",\n",
    "                placeholder=\"Paste your script here...\",\n",
    "                lines=10,\n",
    "                value=\"Hello! This is MOSS text-to-speech, running on Google Colab free tier. Notebook by Danial Gohar at Mozo Technologies.\"\n",
    "            )\n",
    "\n",
    "            reference_audio = gr.Audio(\n",
    "                label=\"üé§ Reference Voice (Optional ‚Äî upload for voice cloning)\",\n",
    "                type=\"filepath\",\n",
    "                sources=[\"upload\"]\n",
    "            )\n",
    "\n",
    "            preset_dropdown = gr.Dropdown(\n",
    "                choices=list(PRESETS.keys()),\n",
    "                value=\"Balanced (16 RVQ)\",\n",
    "                label=\"Preset\"\n",
    "            )\n",
    "\n",
    "            with gr.Row():\n",
    "                max_tokens = gr.Slider(\n",
    "                    50, 5000, 2500, step=100,\n",
    "                    label=\"Max Tokens\"\n",
    "                )\n",
    "                speed = gr.Slider(\n",
    "                    0.5, 2.0, 1.0, step=0.1,\n",
    "                    label=\"Speed\"\n",
    "                )\n",
    "\n",
    "            with gr.Accordion(\"‚öôÔ∏è Advanced Settings\", open=False):\n",
    "                n_vq = gr.Slider(8, 32, 8, step=1, label=\"RVQ Layers\")\n",
    "                with gr.Row():\n",
    "                    text_temp = gr.Slider(0.1, 2.0, 1.5, step=0.1, label=\"Text Temp\")\n",
    "                    text_top_p = gr.Slider(0.1, 1.0, 1.0, step=0.05, label=\"Text Top-P\")\n",
    "                    text_top_k = gr.Slider(1, 100, 50, step=1, label=\"Text Top-K\")\n",
    "                with gr.Row():\n",
    "                    audio_temp = gr.Slider(0.1, 2.0, 0.95, step=0.05, label=\"Audio Temp\")\n",
    "                    audio_top_p = gr.Slider(0.1, 1.0, 0.95, step=0.05, label=\"Audio Top-P\")\n",
    "                with gr.Row():\n",
    "                    audio_top_k = gr.Slider(1, 100, 50, step=1, label=\"Audio Top-K\")\n",
    "                    audio_rep_pen = gr.Slider(1.0, 1.5, 1.1, step=0.05, label=\"Rep Penalty\")\n",
    "\n",
    "            with gr.Row():\n",
    "                generate_btn = gr.Button(\"üéµ Generate Speech\", variant=\"primary\", size=\"lg\", scale=3)\n",
    "                clear_btn = gr.Button(\"üßπ Clear GPU\", variant=\"secondary\", size=\"lg\", scale=1)\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            audio_output = gr.Audio(label=\"üîä Generated Audio\", type=\"filepath\")\n",
    "            status_output = gr.Textbox(label=\"üìä Status\", lines=16, interactive=False)\n",
    "\n",
    "    # ---- FOOTER WITH MOZO BRANDING ----\n",
    "    gr.HTML(\"\"\"\n",
    "    <div class=\"mozo-footer\">\n",
    "        Made with ‚ù§Ô∏è by &nbsp;<b>Danial Gohar</b> &nbsp;|&nbsp; <b>Mozo Technologies</b> &nbsp;|&nbsp;\n",
    "        <a href=\"https://mozotechnologies.com\" target=\"_blank\">üåê mozotechnologies.com</a> &nbsp;|&nbsp;\n",
    "        <a href=\"https://www.linkedin.com/company/mozotech/\" target=\"_blank\">üíº LinkedIn</a>\n",
    "        <br><span style=\"opacity:0.7; font-size:0.85em;\">Found this useful? Connect with us and share! üöÄ</span>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "\n",
    "    preset_dropdown.change(\n",
    "        fn=apply_preset,\n",
    "        inputs=[preset_dropdown],\n",
    "        outputs=[n_vq, text_temp, text_top_p, text_top_k,\n",
    "                audio_temp, audio_top_p, audio_top_k, audio_rep_pen]\n",
    "    )\n",
    "\n",
    "    generate_btn.click(\n",
    "        fn=generate_speech,\n",
    "        inputs=[text_input, reference_audio, max_tokens, speed,\n",
    "                text_temp, text_top_p, text_top_k,\n",
    "                audio_temp, audio_top_p, audio_top_k,\n",
    "                audio_rep_pen, n_vq],\n",
    "        outputs=[audio_output, status_output]\n",
    "    )\n",
    "\n",
    "    def clear_memory():\n",
    "        cleanup_model()\n",
    "        return \"‚úÖ GPU cleared! Ready for next generation.\"\n",
    "\n",
    "    clear_btn.click(fn=clear_memory, inputs=[], outputs=[status_output])\n",
    "\n",
    "print(\"‚úÖ MOSS-TTS ready! Launching Gradio...\")\n",
    "demo.launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ECaq3tQ3-B"
   },
   "source": [
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "### üéâ Found this notebook useful?\n",
    "\n",
    "Connect with us and share with your network!\n",
    "\n",
    "  <a href=\"https://mozotechnologies.com\">\n",
    "    <img src=\"https://img.shields.io/badge/üåê%20Visit%20Website-FF6B00?style=for-the-badge&logoColor=white\" />\n",
    "  </a>\n",
    "  &nbsp;\n",
    "  <a href=\"https://www.linkedin.com/company/mozotech/\">\n",
    "    <img src=\"https://img.shields.io/badge/Follow%20on%20LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white\" />\n",
    "  </a>\n",
    "\n",
    "**Made with ‚ù§Ô∏è by Danial Gohar** | [Mozo Technologies](https://mozotechnologies.com)\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
